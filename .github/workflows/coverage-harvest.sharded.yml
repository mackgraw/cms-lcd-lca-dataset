name: coverage-harvest-sharded

on:
  workflow_dispatch:
    inputs:
      shards:
        description: "Number of shards"
        default: "4"
      max_docs:
        description: "Optional limit for reports list (applied before sharding)"
        default: ""
      timeout:
        description: "HTTP timeout (seconds)"
        default: "30"
  schedule:
    - cron: "0 6 * * *"  # daily at 06:00 UTC

jobs:
  harvest:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        shard: [0, 1, 2, 3]   # keep 0-based; edit if you change shards
        total: [4]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run shard
        env:
          COVERAGE_TIMEOUT: ${{ github.event.inputs.timeout || '30' }}
          COVERAGE_MAX_DOCS: ${{ github.event.inputs.max_docs || '' }}
          SHARD_INDEX: ${{ matrix.shard }}
          SHARD_TOTAL: ${{ matrix.total }}
        run: |
          python -m scripts.harvest_shard

      - name: Upload shard outputs
        uses: actions/upload-artifact@v4
        with:
          name: shard-${{ matrix.shard }}-of-${{ matrix.total }}
          path: |
            dataset/document_codes_shard_${{ matrix.shard }}_of_${{ matrix.total }}.csv
            dataset/document_nocodes_shard_${{ matrix.shard }}_of_${{ matrix.total }}.csv

  merge:
    runs-on: ubuntu-latest
    needs: harvest
    steps:
      - uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Merge CSVs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p dataset

          merge_one() {
            pattern="$1"
            out="$2"

            : > "$out"
            first=1
            # sort guarantees stable header-first if shard 0 exists; tail -n +2 drops headers
            while IFS= read -r -d '' f; do
              if [ $first -eq 1 ]; then
                cat "$f" >> "$out"
                first=0
              else
                tail -n +2 "$f" >> "$out"
              fi
            done < <(find artifacts -type f -name "$pattern" -print0 | sort -z)
          }

          merge_one "document_codes_shard_*_of_*.csv" "dataset/document_codes.csv"
          merge_one "document_nocodes_shard_*_of_*.csv" "dataset/document_nocodes.csv"

      - name: Upload merged dataset
        uses: actions/upload-artifact@v4
        with:
          name: dataset-merged
          path: dataset/*.csv
